{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dahouda2pro/ViT_Using_Bayesian_Opt/blob/master/ViT_Bayesian_Opt_Satellite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzDgDgfttglL",
        "outputId": "dc073664-dbbe-4f6d-84e4-c8259ca3f1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPy\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.4/959.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from GPy) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from GPy) (1.16.0)\n",
            "Collecting paramz>=0.9.0 (from GPy)\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from GPy) (3.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from GPy) (1.11.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from paramz>=0.9.0->GPy) (4.4.2)\n",
            "Building wheels for collected packages: GPy, paramz\n"
          ]
        }
      ],
      "source": [
        "# Install GPy, GPyOpt\n",
        "!pip install GPy\n",
        "!pip install GPyOpt\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hlq1kM6jEnJ"
      },
      "outputs": [],
      "source": [
        "# Install GPy, GPyOpt\n",
        "##!pip install GPy==1.9.8\n",
        "#!pip install GPyOpt==1.2.1\n",
        "#!pip install tensorflow-addons\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras as K\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import GPy\n",
        "import GPyOpt\n",
        "from GPyOpt.methods import BayesianOptimization\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import LeakyReLU\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCjOM9wTjdwT"
      },
      "outputs": [],
      "source": [
        "!python3 --version\n",
        "#Python 3.6.9\n",
        "print(tf.__version__)\n",
        "#2.3.0\n",
        "#print(K.__version__)\n",
        "#2.4.0\n",
        "print(np.__version__)\n",
        "#1.18.5\n",
        "#print(matplotlib.__version__)\n",
        "#3.2.2\n",
        "print(GPy.__version__)\n",
        "#1.9.8\n",
        "print(GPyOpt.__version__)\n",
        "#1.2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to my google drive\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FhABRWCtTeC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR= '/content/drive/MyDrive/Satellite_Images/data'\n",
        "CATEGORIES = os.listdir(DATADIR)\n",
        "print(CATEGORIES)"
      ],
      "metadata": {
        "id": "MxkBANN_ZS1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading images"
      ],
      "metadata": {
        "id": "0yPXoI4TZfoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(DATADIR, CATEGORIES):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    nb_images_each_type = []\n",
        "    for category in CATEGORIES:\n",
        "        beginning = len(images)\n",
        "        class_number = CATEGORIES.index(category)\n",
        "        path = os.path.join(DATADIR, category)\n",
        "        for img in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, img))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (256,256))\n",
        "            images.append(img)\n",
        "            labels.append(class_number)\n",
        "\n",
        "            # Adding rotated image\n",
        "            param = random.choice([-180, -90, 90])\n",
        "            if param == -180:\n",
        "                img_rotated = cv2.rotate(img, cv2.ROTATE_180)\n",
        "            elif param == -90:\n",
        "                img_rotated = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "            elif param == 90:\n",
        "                img_rotated = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "            images.append(img_rotated)\n",
        "            labels.append(class_number)\n",
        "\n",
        "            # Adding rotated and cropped image\n",
        "            img_cropped = img[32:224, 32:224]\n",
        "            param = random.choice([-180, -90, 90])\n",
        "            if param == -180:\n",
        "                img_cropped = cv2.rotate(img_cropped, cv2.ROTATE_180)\n",
        "            elif param == -90:\n",
        "                img_cropped = cv2.rotate(img_cropped, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "            elif param == 90:\n",
        "                img_cropped = cv2.rotate(img_cropped, cv2.ROTATE_90_CLOCKWISE)\n",
        "            img_cropped = cv2.resize(img_cropped, (256,256))\n",
        "            images.append(img_cropped)\n",
        "            labels.append(class_number)\n",
        "\n",
        "        end = len(images)\n",
        "        nb_images_each_type.append(end-beginning)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Displaying dataset info\n",
        "    print(f'images: {len(images)}; labels: {len(labels)}')\n",
        "    print('image size:', images[0].shape)\n",
        "    print('-'*25)\n",
        "    print('number of images of each label:')\n",
        "    for i in range(len(CATEGORIES)):\n",
        "        print(f'{CATEGORIES[i]}: {nb_images_each_type[i]}')\n",
        "    print('-'*25)\n",
        "    from sys import getsizeof\n",
        "    print(f'size of dataset: {getsizeof(images)/1024/1024} MB; {getsizeof(images)/1024/1024/1024} GB')\n",
        "    plt.imshow(images[random.randint(0, len(images))])\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "JWfE-fgyZgvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = load_images(DATADIR, CATEGORIES)"
      ],
      "metadata": {
        "id": "owAqmjv_ZSxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test data and making labels categorical"
      ],
      "metadata": {
        "id": "9sHLjYJZV3dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, train_size=.85, random_state=1)\n",
        "images, labels = 0, 0"
      ],
      "metadata": {
        "id": "dqGMR5gqbDFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-_wEz4ijx8F"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_classes = 4\n",
        "input_shape = (256, 256, 3)\n",
        "IMG_DIM = 256\n",
        "\n",
        "#(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZP1mwpAj4ei"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "input_tensor = K.Input(shape=(256, 256, 3))\n",
        "# resize images to the image size upon which the network was pre-trained\n",
        "resized_images = K.layers.Lambda(lambda image: tf.image.resize(image, (331, 331)))(input_tensor)\n",
        "base_model = K.applications.NASNetLarge(include_top=False,\n",
        "                                        weights='imagenet',\n",
        "                                        input_tensor=resized_images,\n",
        "                                        input_shape=(331, 331, 3),\n",
        "                                        pooling='max',\n",
        "                                        classes=num_classes)\n",
        "output = base_model.layers[-1].output\n",
        "base_model = K.models.Model(inputs=input_tensor, outputs=output)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9W7RYmKkBmw"
      },
      "outputs": [],
      "source": [
        "# using the training data\n",
        "\"\"\"\n",
        "train_datagen = K.preprocessing.image.ImageDataGenerator()\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32, shuffle=False)\n",
        "features_train = base_model.predict(train_generator)\n",
        "\n",
        "# repeat the same operation with the test data (here used for validation)\n",
        "val_datagen = K.preprocessing.image.ImageDataGenerator()\n",
        "val_generator = val_datagen.flow(x_test, y_test, batch_size=32, shuffle=False)\n",
        "features_valid = base_model.predict(val_generator)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_datagen = ImageDataGenerator().flow_from_dataframe(x_train, target_size=(IMG_DIM, IMG_DIM), classes=num_classes,)\n",
        "\n",
        "#val_gen = ImageDataGenerator().flow_from_dataframe(x_test, target_size=(IMG_DIM, IMG_DIM), classes=CLASSES, shuffle=False,)\n",
        "\n",
        "#test_gen = ImageDataGenerator().flow_from_dataframe(x_test, target_size=(IMG_DIM, IMG_DIM), classes=num_classes, shuffle=False,)"
      ],
      "metadata": {
        "id": "tma_4I1ogxnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3CXRO_3kbq3"
      },
      "outputs": [],
      "source": [
        "def build_model(units=256, learning_rate=1e-4, l2=1e-2, activation=2, rate=0.5):\n",
        "  \"\"\"function that builds a model for the head classifier\"\"\"\n",
        "  # weights are initialized as per the he et al. method\n",
        "  initializer = K.initializers.he_normal()\n",
        "  input_tensor = K.Input(shape=(256,))\n",
        "  activation_dict = {1: 'relu', 2: 'elu', 3: 'tanh', 4: 'sigmoid', 5: 'softplus'}\n",
        "#activation_dict = {1: 'relu', 2: 'elu', 3: 'tanh', 4: 'sigmoid', 5: 'softplus', 6: 'softsign', 7: 'selu'}\n",
        "  layer = K.layers.Dense(units=units,\n",
        "                         activation=activation_dict[activation],\n",
        "                         kernel_initializer=initializer,\n",
        "                        kernel_regularizer=K.regularizers.l2(l2=l2))\n",
        "  output = layer(input_tensor)\n",
        "  dropout = K.layers.Dropout(rate)\n",
        "  output = dropout(output)\n",
        "  softmax = K.layers.Dense(units=num_classes,\n",
        "                           activation='softmax',\n",
        "                           kernel_initializer=initializer,\n",
        "                        kernel_regularizer=K.regularizers.l2(l2=l2))\n",
        "  output = softmax(output)\n",
        "  model = K.models.Model(inputs=input_tensor, outputs=output)\n",
        "  # compile the densely-connected head classifier (here, \"model\")\n",
        "  model.compile(\n",
        "           optimizer=K.optimizers.Adam(learning_rate=learning_rate),\n",
        "           loss='categorical_crossentropy',\n",
        "           metrics=['accuracy'])\n",
        "  # Define some callback functions to be used by the model during training\n",
        "  # reduce learning rate when val_accuracy has stopped improving\n",
        "  lr_reduce = K.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                            factor=0.6,\n",
        "                                            patience=2,\n",
        "                                            verbose=1,\n",
        "                                            mode='max',\n",
        "                                            min_lr=1e-7)\n",
        "  # stop training when val_accuracy has stopped improving\n",
        "  early_stop = K.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "                                         patience=3,\n",
        "                                         verbose=1,\n",
        "                                         mode='max')\n",
        "  # callback to save the Keras model and (best) weights obtained on an epoch basis\n",
        "  checkpoint = K.callbacks.ModelCheckpoint('cifar100.h5',\n",
        "                                           monitor='val_accuracy',\n",
        "                                           verbose=1,\n",
        "                                           save_weights_only=False,\n",
        "                                           save_best_only=True,\n",
        "                                           mode='max',\n",
        "                                           save_freq='epoch')\n",
        "  return model, lr_reduce, early_stop, checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAE_Gqx_n4e1"
      },
      "outputs": [],
      "source": [
        "def fit_model(model, lr_reduce, early_stop, checkpoint):\n",
        "  \"\"\"function that trains the head classifier\"\"\"\n",
        "  history = model.fit(x_train, y_train,\n",
        "                      batch_size=32,\n",
        "                      epochs=50,\n",
        "                      verbose=1,\n",
        "                      callbacks=[lr_reduce, early_stop, checkpoint],\n",
        "                      validation_data=(x_test, y_test),\n",
        "                      shuffle=True)\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECnC14nen-f4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model):\n",
        "  \"\"\"function that evaluates the head classifier\"\"\"\n",
        "  evaluation = model.evaluate(x_test, y_test)\n",
        "  return evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd4V73OPoH5o"
      },
      "outputs": [],
      "source": [
        "# define the kernel for the Bayesian surrogate model using the \"radial basis function\" (RBF)\n",
        "kernel = GPy.kern.RBF(input_dim=1, variance=1.0, lengthscale=1.0)\n",
        "# hyperparameter bounds\n",
        "bounds = [\n",
        "    {'name': 'units', 'type': 'discrete', 'domain': (32, 64, 128, 256)},\n",
        "    {'name': 'learning_rate', 'type': 'discrete', 'domain': (1e-3, 1e-4, 1e-5, 1e-6)},\n",
        "    {'name': 'l2', 'type': 'discrete', 'domain': (1e-1, 1e-2, 1e-3)},\n",
        "    {'name': 'activation', 'type': 'discrete', 'domain': (1, 2, 3, 4, 5)},\n",
        "    {'name': 'rate', 'type': 'discrete', 'domain': (0.25, 0.5, 0.75)}]\n",
        "# Note: 'activation' domain parameters (1, 2, 3, 4, 5, 6, 7) correspond to strings ('relu', 'elu', 'tanh','sigmoid', 'softplus', 'softsign', 'selu); dictionary defined in build_model()\n",
        "# objective function for the model optimization:\n",
        "def f(x):\n",
        "  \"\"\"objective function of the Bayesian surrogate model\"\"\"\n",
        "  print()\n",
        "  print(\"Hyperparameters:\", x)\n",
        "  # Retrieve 'accuracy' from the previously saved model\n",
        "  try:\n",
        "    previous_best_model = K.models.load_model('satellite_best.h5')\n",
        "    previous_evaluation = evaluate_model(previous_best_model)\n",
        "  except Exception:\n",
        "    previous_best_model = None\n",
        "  model, lr_reduce, early_stop, checkpoint = build_model(\n",
        "                                        units=int(x[:,0]),\n",
        "                                        learning_rate=float(x[:,1]),\n",
        "                                        l2=float(x[:,2]),\n",
        "                                        activation=int(x[:,3]),\n",
        "                                        rate=float(x[:,4]))\n",
        "  history = fit_model(model, lr_reduce, early_stop, checkpoint)\n",
        "  evaluation = evaluate_model(model)\n",
        "  print()\n",
        "  print(\"LOSS:\\t{0} \\t ACCURACY:\\t{1}\".format(evaluation[0],\n",
        "  evaluation[1]))\n",
        "  print(evaluation)\n",
        "  print()\n",
        "  # compare previous and current validation accuracies\n",
        "  if not previous_best_model:\n",
        "    K.models.save_model(model, 'satellite_best.h5', overwrite=False,\n",
        "    include_optimizer=True)\n",
        "  if previous_best_model and evaluation[1] > previous_evaluation[1]:\n",
        "    K.models.save_model(model, 'satellite_best.h5', overwrite=True,\n",
        "    include_optimizer=True)\n",
        "  # Get the dictionary containing each metric and the loss for each epoch\n",
        "  # history_dict = history.history\n",
        "  # print(history_dict)\n",
        "  plot = 0\n",
        "  def plot_history(history):\n",
        "    plt.figure(1, figsize = (15,8))\n",
        "    plt.subplot(221)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train', 'Valid'])\n",
        "    plt.subplot(222)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train', 'Valid'])\n",
        "    plot = 0\n",
        "    plt.savefig('Loss_Acc_'+str(plot)+'.pdf')\n",
        "    plt.savefig('Loss_Acc_'+str(plot)+'.png')\n",
        "    plot = plot + 1\n",
        "    plt.show()\n",
        "\n",
        "  # plot the model accuracy and loss results\n",
        "  plot_history(history)\n",
        "  # delete the instantiated models from memory and clear the session\n",
        "  del model\n",
        "  del previous_best_model\n",
        "  K.backend.clear_session()\n",
        "  return evaluation[1]\n",
        "# Initializing X and Y, and adding noise (if need be)\n",
        "# X_init = np.array([[int(16)]])\n",
        "# Y_init = f(X_init)\n",
        "# noise = 0.2\n",
        "optimizer = BayesianOptimization(f=f,\n",
        "                                 domain=bounds,\n",
        "                                 model_type='GP',\n",
        "                                 kernel=kernel,\n",
        "                                 acquisition_type ='EI',\n",
        "                                 acquisition_jitter = 0.01,\n",
        "                                 exact_feval=False,\n",
        "                                 normalize_Y=False,\n",
        "                                 maximize=True,\n",
        "                                 verbosity=False)\n",
        "print()\n",
        "print(\"=====================\")\n",
        "print(\"=====================\")\n",
        "print()\n",
        "optimizer.run_optimization(max_iter=4, verbosity=False)\n",
        "optimizer.plot_acquisition()\n",
        "optimizer.plot_convergence()\n",
        "optimizer.save_report('bayes_opt.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8bXHx-js8XO"
      },
      "outputs": [],
      "source": [
        "# print optimized model\n",
        "#activation_dict = {1: 'relu', 2: 'elu', 3: 'tanh'}\n",
        "activation_dict = {1: 'relu', 2: 'elu', 3: 'tanh', 4: 'sigmoid', 5: 'softplus'}\n",
        "print(\"\"\"\n",
        "Optimized Parameters:\n",
        "\\t{0}:\\t{1}\n",
        "\\t{2}:\\t{3}\n",
        "\\t{4}:\\t{5}\n",
        "\\t{6}:\\t{7}\n",
        "\\t{8}:\\t{9}\n",
        "\"\"\".format(bounds[0][\"name\"], optimizer.x_opt[0],\n",
        "           bounds[1][\"name\"], optimizer.x_opt[1],\n",
        "           bounds[2][\"name\"], optimizer.x_opt[2],\n",
        "           bounds[3][\"name\"], activation_dict[optimizer.x_opt[3]],\n",
        "           bounds[4][\"name\"], optimizer.x_opt[4]))\n",
        "print(\"optimized accuracy: {0}\".format(abs(optimizer.fx_opt)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKaosz-Tvp51"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS8EQ23utrwp"
      },
      "outputs": [],
      "source": [
        "# reinstantiate the best model from saved file\n",
        "best_model = K.models.load_model('cifar100_best.h5')\n",
        "best_model.summary()\n",
        "loss, acc = best_model.evaluate(features_valid, y_test)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt76hdbAty2W"
      },
      "outputs": [],
      "source": [
        "best_model.evaluate(features_valid, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_qSuEiyt2c_"
      },
      "outputs": [],
      "source": [
        "data_path = 'bayes_opt.txt'\n",
        "with open(data_path, 'r') as f:\n",
        "  lines = f.read().split('\\n')\n",
        "for line in lines:\n",
        "  print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0XGEUvHEugy"
      },
      "source": [
        "Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO4TxKdHEvau"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    input_size = 32\n",
        "    input_shape = [input_size, input_size, 3]\n",
        "    learning_rate = 0.001\n",
        "    weight_decay = 0.0001\n",
        "    batch_size = 256\n",
        "    num_classes = 100\n",
        "    num_epochs = 100\n",
        "    image_size = 72\n",
        "    patch_size = 6\n",
        "    num_patches = (image_size // patch_size) ** 2\n",
        "    projection_dim = 64\n",
        "    num_heads = 4\n",
        "    transformer_units = [\n",
        "        projection_dim * 2,\n",
        "        projection_dim\n",
        "    ]\n",
        "    transformer_layers = 8\n",
        "    mlp_head_units = [2048, 1024]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfmIomO2PIjL"
      },
      "outputs": [],
      "source": [
        "def sample_images(images, row_count, column_count):\n",
        "    fig, axs = plt.subplots(row_count, column_count, figsize=(10,10))\n",
        "    for i in range(row_count):\n",
        "        for j in range(column_count):\n",
        "            axs[i,j].imshow(images[i * column_count + j])\n",
        "            axs[i,j].axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHyHd_8MPN0M"
      },
      "outputs": [],
      "source": [
        "(train_data, train_labels),(test_data, test_labels)  = keras.datasets.cifar100.load_data()\n",
        "(train_data.shape, train_labels.shape),(test_data.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR04yzlYPTtR"
      },
      "outputs": [],
      "source": [
        "indices = np.random.choice(train_data.shape[0], 100)\n",
        "sample_images(train_data[indices], 10, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD3VAtmHFSFS"
      },
      "source": [
        " Use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ypjf7bbgFPSj"
      },
      "outputs": [],
      "source": [
        "augmentation_layer = tf.keras.Sequential([\n",
        "    keras.layers.Input(Config.input_shape),\n",
        "    keras.layers.experimental.preprocessing.Normalization(),\n",
        "    keras.layers.experimental.preprocessing.Resizing(Config.image_size, Config.image_size),\n",
        "    keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
        "    keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM5RaTBgPm-Q"
      },
      "outputs": [],
      "source": [
        "augmentation_layer.layers[0].adapt(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV-bwQ8uFA4i"
      },
      "source": [
        " Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT7ZcYO2FDIi"
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3iTa5LFFHG1"
      },
      "outputs": [],
      "source": [
        "# Implement patch creation as a layer\n",
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images = images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCKyCO-rGOOx"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = train_data[np.random.choice(range(train_data.shape[0]))]\n",
        "print(image.shape)\n",
        "plt.imshow(np.squeeze(image).astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(Config.image_size, Config.image_size)\n",
        ")\n",
        "print(resized_image.shape)\n",
        "patches = Patches(Config.patch_size)(resized_image)\n",
        "print(f\"Image size: {Config.image_size} X {Config.image_size}\")\n",
        "print(f\"Patch size: {Config.patch_size} X {Config.patch_size}\")\n",
        "print(f\"Patches Sahpe: {patches.shape}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (Config.patch_size, Config.patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW9N1wYKG9HP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The PatchEncoder layer will linearly transform a patch by projecting it into a vector of size projection_dim. In addition, it adds a learnable position embedding to the projected vector.\n",
        "\n",
        "\"\"\"\n",
        "class PatchEncoder(layers.Layer):\n",
        "\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM5pzvdTHB3B"
      },
      "source": [
        "Build the ViT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCdCovoDHF_x"
      },
      "outputs": [],
      "source": [
        "def create_vision_transformer():\n",
        "    # Inputs\n",
        "    inputs = layers.Input(shape=Config.input_shape)\n",
        "    # Data Augmentation\n",
        "    augmented = augmentation_layer(inputs)\n",
        "    # Patches\n",
        "    patches = Patches(Config.patch_size)(augmented)\n",
        "    encoder_patches = PatchEncoder(Config.num_patches, Config.projection_dim)(patches)\n",
        "\n",
        "    for _ in range(Config.transformer_layers):\n",
        "        # Layer Normalization 1\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoder_patches)\n",
        "        # Multi-Head Attention Layer\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=Config.num_heads,\n",
        "            key_dim=Config.projection_dim,\n",
        "            dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip Connnection 1\n",
        "        x2 = layers.Add()([attention_output, encoder_patches])\n",
        "\n",
        "        # Layer Normalization 2\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "\n",
        "        # MLP\n",
        "        x3 = mlp(x3, hidden_units=Config.transformer_units, dropout_rate=0.1)\n",
        "\n",
        "        # Skip Connnection 2\n",
        "        encoder_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoder_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "\n",
        "    features = mlp(representation, hidden_units=Config.mlp_head_units, dropout_rate=0.5)\n",
        "\n",
        "    outputs = layers.Dense(Config.num_classes)(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrXbzzmwHpet"
      },
      "source": [
        "Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSHrm_QKHnUk"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "vit_classifier = create_vision_transformer()\n",
        "vit_classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INv8yE7iQIFE"
      },
      "outputs": [],
      "source": [
        "optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=Config.learning_rate,\n",
        "    weight_decay=Config.weight_decay\n",
        ")\n",
        "vit_classifier.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "checkpoint_path = \"model.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zgZKojxQMgS"
      },
      "outputs": [],
      "source": [
        "history = vit_classifier.fit(train_data, train_labels, verbose=1, epochs=50, batch_size=Config.batch_size, validation_data=(test_data, test_labels), callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ6zmc07YBAY"
      },
      "outputs": [],
      "source": [
        "  # print(history_dict)\n",
        "plot = 0\n",
        "def plot_history(history):\n",
        "    plt.figure(1, figsize = (15,8))\n",
        "    plt.subplot(221)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train', 'Valid'])\n",
        "    plt.subplot(222)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train', 'Valid'])\n",
        "    plot = 0\n",
        "    plt.savefig('Loss_Acc_'+str(plot)+'.pdf')\n",
        "    plt.savefig('Loss_Acc_'+str(plot)+'.png')\n",
        "    plot = plot + 1\n",
        "    plt.show()\n",
        "\n",
        "  # plot the model accuracy and loss results\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#_,accuracy, top_5_accuracy = vit_classifier(test_data, test_labels)\n",
        "#print(f\"Test Accuracy: {round(accuracy * 100)}%\")\n",
        "#print(f\"Test Top 5 Accuracy: {round(top_5_accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "id": "YhRTyAijsdOc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY8mCjBuTHeNllLN/+lS3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}